{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import conf as cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "root = cf.path_data\n",
    "encoding = cf.encoding\n",
    "data_path = os.path.join(root,\"01-bio_v1-manual.csv\")\n",
    "model_bert_name = cf.model_bert\n",
    "df = pd.read_csv(data_path,encoding=encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_bert_name)\n",
    "\n",
    "# Encode the labels for intent detection\n",
    "label_encoder = LabelEncoder()\n",
    "df['intent_label'] = label_encoder.fit_transform(df['intent'])\n",
    "\n",
    "# Prepare data for NER\n",
    "# In this example, we'll assume the 'bio_tags' column is already encoded with BIO tagging\n",
    "# Modify this part based on your actual data preparation for NER\n",
    "# The 'bio_tags' column should be a list of lists of encoded tags\n",
    "# Each encoded tag corresponds to a token in the text\n",
    "df['ner_tags'] = df['bio_tags'].apply(eval)  # Convert the string representation of lists to actual lists\n",
    "\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the tag mapping for NER\n",
    "tag_map = {\n",
    "    'O': 0,\n",
    "    'B-place': 1,\n",
    "    'I-place': 2,\n",
    "    'B-crop': 3,\n",
    "    'I-crop': 4,\n",
    "    'B-measure': 5,\n",
    "    'I-measure': 6,\n",
    "    'B-date': 7,\n",
    "    'I-date': 8\n",
    "}\n",
    "\n",
    "# Tokenize and encode the text data for NER\n",
    "def encode_tags(tags, max_len):\n",
    "    encoded_tags = []\n",
    "    for tag in tags:\n",
    "        encoded_tag = [tag_map.get(t, 0) for t in tag[:max_len]]\n",
    "        encoded_tag.extend([0] * (max_len - len(encoded_tag)))\n",
    "        encoded_tags.append(encoded_tag)\n",
    "    return np.array(encoded_tags)\n",
    "\n",
    "# Tokenize and encode the text data for intent detection\n",
    "encoded_texts = tokenizer(train_df['text'].tolist(), padding=True, truncation=True, return_tensors='tf')\n",
    "intent_labels = tf.keras.utils.to_categorical(train_df['intent_label'], num_classes=len(label_encoder.classes_))\n",
    "ner_tags = encode_tags(train_df['ner_tags'], max_len=len(encoded_texts['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the BERT-based model with two outputs\n",
    "def build_model(num_intent_labels, num_ner_labels, max_len):\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "    bert_model = TFBertModel.from_pretrained(model_bert_name)\n",
    "    bert_outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "    pooled_output = bert_outputs.pooler_output\n",
    "    intent_output = Dense(num_intent_labels, activation='softmax', name=\"intent_output\")(pooled_output)\n",
    "    ner_output = Dense(num_ner_labels, activation='softmax', name=\"ner_output\")(bert_outputs.last_hidden_state)\n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=[intent_output, ner_output])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Number of intent labels and NER labels\n",
    "num_intent_labels = len(label_encoder.classes_)\n",
    "num_ner_labels = len(tag_map)\n",
    "\n",
    "# Max sequence length for padding\n",
    "max_len = max(encoded_texts['input_ids'].shape[1], ner_tags.shape[1])\n",
    "\n",
    "print(\"Model parameters\",num_intent_labels,num_ner_labels,max_len)\n",
    "# Build the model\n",
    "model = build_model(num_intent_labels, num_ner_labels, max_len)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=5e-5),\n",
    "              loss={'intent_output': 'categorical_crossentropy', 'ner_output': 'sparse_categorical_crossentropy'},\n",
    "              metrics={'intent_output': 'accuracy', 'ner_output': 'accuracy'})\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard callback\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    {'input_ids': encoded_texts['input_ids'], 'attention_mask': encoded_texts['attention_mask']},\n",
    "    {'intent_output': intent_labels, 'ner_output': ner_tags},\n",
    "    validation_split=0.3,\n",
    "    epochs=15,\n",
    "    batch_size=30,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode the text data for the test set\n",
    "encoded_texts_test = tokenizer(test_df['text'].tolist(),padding='max_length',truncation=True,max_length=max_len, return_tensors='tf')\n",
    "intent_labels_test = tf.keras.utils.to_categorical(test_df['intent_label'], num_classes=len(label_encoder.classes_))\n",
    "ner_tags_test = encode_tags(test_df['ner_tags'], max_len=max_len)\n",
    "\n",
    "intent_loss, intent_accuracy, _, ner_loss, ner_accuracy = model.evaluate(\n",
    "    {'input_ids': encoded_texts['input_ids'], 'attention_mask': encoded_texts['attention_mask']},\n",
    "    {'intent_output': intent_labels, 'ner_output': ner_tags},\n",
    ")\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_intent_accuracy, _, test_ner_loss, test_ner_accuracy = model.evaluate(\n",
    "    {'input_ids': encoded_texts_test['input_ids'], 'attention_mask': encoded_texts_test['attention_mask']},\n",
    "    {'intent_output': intent_labels_test, 'ner_output': ner_tags_test},\n",
    ")\n",
    "\n",
    "print(\"Evalutation Training\",\"Intent Loss:\", intent_loss,\"Intent Accuracy:\", intent_accuracy,\"NER Loss:\", ner_loss,\"NER Accuracy:\", ner_accuracy)\n",
    "print(\"Evalutation Test\",\"Intent Loss:\", test_loss,\"Intent Accuracy:\", test_intent_accuracy,\"NER Loss:\", test_ner_loss,\"NER Accuracy:\", test_ner_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot performance modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot model performance\n",
    "def plot_model_performance(history):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    # Plot training & validation accuracy values - intent\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history.history['intent_output_accuracy'])\n",
    "    plt.plot(history.history['val_intent_output_accuracy'])\n",
    "    plt.title('Model Intent Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    # Plot training & validation loss values - intent\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history.history['intent_output_loss'])\n",
    "    plt.plot(history.history['val_intent_output_loss'])\n",
    "    plt.title('Model Intent Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    # Plot training & validation accuracy values - ner\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history.history['ner_output_accuracy'])\n",
    "    plt.plot(history.history['val_ner_output_accuracy'])\n",
    "    plt.title('Model NER Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    # Plot training & validation loss values - ner\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(history.history['ner_output_loss'])\n",
    "    plt.plot(history.history['val_ner_output_loss'])\n",
    "    plt.title('Model NER Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(os.path.join(root,\"performance.png\"), format='png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Plot model performance\n",
    "plot_model_performance(history)\n",
    "\n",
    "##########\n",
    "test_predictions = model.predict({'input_ids': encoded_texts_test['input_ids'], 'attention_mask': encoded_texts_test['attention_mask']})\n",
    "\n",
    "# Extract predicted intent labels and NER tags\n",
    "predicted_intent_labels_test = test_predictions[0].argmax(axis=1)\n",
    "predicted_ner_labels_test = test_predictions[1].argmax(axis=2).flatten()\n",
    "\n",
    "def plot_confusion_matrix(intent_conf_matrix,ner_conf_matrix):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    # Plot training & validation accuracy values - intent\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(intent_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Intent Confusion Matrix')\n",
    "    # Plot confusion matrix for NER\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(ner_conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=tag_map.keys(), yticklabels=tag_map.keys())\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('NER Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(os.path.join(root,\"confusion_matrix.png\"), format='png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "# Plot confusion matrix for intent\n",
    "intent_conf_matrix = confusion_matrix(test_df['intent_label'], predicted_intent_labels_test)\n",
    "ner_conf_matrix = confusion_matrix(ner_tags_test.flatten(), predicted_ner_labels_test)\n",
    "plot_confusion_matrix(intent_conf_matrix,ner_conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demeter_path = os.path.join(root,\"demeter_model\")\n",
    "tf.keras.models.save_model(model,demeter_path)\n",
    "\n",
    "intent_label_encoder_file = os.path.join(root, 'intent_label_encoder.txt')\n",
    "with open(intent_label_encoder_file, 'w') as f:\n",
    "    for label in label_encoder.classes_:\n",
    "        f.write(label + '\\n')\n",
    "\n",
    "# Fit and transform labels for NER entities\n",
    "ner_labels = [label for label in tag_map.keys() if label != 'O']\n",
    "ner_labels_file = os.path.join(root, 'ner_labels.txt')\n",
    "with open(ner_labels_file, 'w') as f:\n",
    "    for label in ner_labels:\n",
    "        f.write(label + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
